
# **Abstract**
The deployment of large language models (LLMs) within the healthcare sector has sparked both enthusiasm and apprehension. These models exhibit the remarkable capability to provide profi- cient responses to free-text queries, demonstrating a nuanced understanding of professional medical knowledge. This comprehensive survey delves into the functionalities of existing LLMs designed for healthcare applications, elucidating the trajectory of their development, starting from traditional Pretrained Language Models (PLMs) to the present state of LLMs in healthcare sector. First, we explore the potential of LLMs to amplify the efficiency and effectiveness of diverse healthcare appli- cations, particularly focusing on clinical language understanding tasks. These tasks encompass a wide spectrum, ranging from named entity recognition and relation extraction to natural language inference, multi-modal medical applications, document classification, and question-answering. Additionally, we conduct an extensive comparison of the most recent state-of-the-art LLMs in the healthcare domain, while also assessing the utilization of various open-source LLMs and highlighting their significance in healthcare applications. Furthermore, we present the essential performance metrics employed to evaluate LLMs in the biomedical domain, shedding light on their effectiveness and limitations. Finally, we summarize the prominent challenges and constraints faced by large language models in the healthcare sector, offering a holistic perspective on their potential benefits and shortcomings. This review provides a comprehensive exploration of the current landscape of LLMs in healthcare, addressing their role in transforming medical applications and the areas that warrant further research and development.

***K*eywords** Large Language Model *·* Healthcare *·* Medicine *·* Natural Language Generation *·* Natural Language Processing *·* Machine Learning Applications *·* ChatGPT *·* Generative AI *·* Medical AI

1. # <a name="introduction"></a>**Introduction**
Deep Learning provides an intelligent way to understand human behaviors, emotions and human healthcare [[1](#_bookmark9), [2](#_bookmark10), [3](#_bookmark11), [4](#_bookmark12)]. Recent developments in clinical language understanding have ushered in the potential for a paradigm shift in the healthcare sector. These advancements hold the promise of ushering in a new era characterized by the deployment of intelligent systems designed to bolster decision-making, expedite diagnostic processes, and elevate the quality of patient care. In essence, these systems have the capacity to serve as indispensable aids to healthcare professionals as they grapple with the ever-expanding body of medical knowledge, decipher intricate patient records, and formulate highly tailored treatment plans. This transformative potential has ignited considerable enthusiasm within the healthcare community [\[5,](#_bookmark13) [6,](#_bookmark14) [7\].](#_bookmark15)

The immense value of lage language models (LLMs) lies in their ability to process and synthesize colossal volumes of medical literature, patient records, and the ever-expanding body of clinical research. Healthcare data [[8](#_bookmark16), [9](#_bookmark17)] is inherently complex, heterogeneous, and often overwhelming in scale. LLMs act as a powerful force multiplier, aiding healthcare professionals struggling with information overload. By automating the analysis of medical texts, extracting crucial insights, and applying that knowledge, LLMs are poised to drive groundbreaking research and enhance patient care, significantly improving and contributing to the progression of the healthcare and medical domain.




Notably, this surge of enthusiasm is attributable, in part, to the exceptional performance of state-of-the-art large language models (LLMs) such as OpenAI’s GPT-3.5, GPT-4 [[10](#_bookmark18), [11](#_bookmark19)], and Google’s Bard. These models have exhibited remarkable proficiency in a wide spectrum of natural language understanding tasks, highlighting their pivotal role in healthcare. Their ability to comprehend and generate human-like text is poised to play a transformative role in healthcare practices, where effective communication and information processing are of paramount importance [\[12\].](#_bookmark20)

The trajectory of natural language processing (NLP) has been characterized by a series of noteworthy milestones, with each development building upon the strengths and limitations of its predecessors. In its nascent stages, recurrent neural networks (RNNs) laid the foundation for contextual information retention in NLP tasks. However, their inherent limitations in capturing long-range dependencies became evident, thus necessitating a shift in the NLP paradigm.

The pivotal moment in NLP’s evolution came with the introduction of Transformers, a groundbreaking architecture that addressed the challenge of capturing distant word relationships effectively. This innovation was a turning point, enabling more advanced NLP models. These advancements provided the impetus for the emergence of sophisticated language models like Llama 2 [[13](#_bookmark21)] and GPT-4, which, underpinned by extensive training data, have elevated NLP to a level of understanding and text generation that closely approximates human-like language.

Within the healthcare domain, tailored adaptations of models like BERT, including BioBERT and ClinicalBERT [[14](#_bookmark22), [15](#_bookmark23)], were introduced to tackle the intricacies of clinical language. The introduction of these models addressed the unique challenges posed by medical text, which frequently features complex medical terminology, lexical ambiguity, and variable usage. However, introducing LLMs into the highly sensitive and regulated domain of healthcare demands careful consideration of ethics, privacy, and security. Patient data must be rigorously protected, while ensuring that LLMs don’t perpetuate existing biases or lead to unintended harm. Nevertheless, the potential for LLMs to enhance healthcare practices, better patient outcomes, and spearhead innovative research avenues continues to stimulate ongoing investigation and growth in this rapidly evolving field.

As we navigate this dynamic field, our review aims to function as a comprehensive guide, offering insights to medical researchers and healthcare professionals seeking to optimize their research endeavors and clinical practices. We seek to provide a valuable resource for the judicious selection of LLMs tailored to specific clinical requirements. Our examination encompasses a detailed exploration of LLMs within the healthcare domain, elucidating their underlying technology, diverse healthcare applications, and facilitating discussions on critical topics such as fairness, bias mitigation, privacy, transparency, and ethical considerations. By highlighting these critical aspects, this review aims to illustrate the importance of integrating LLMs into healthcare in a manner that is not only effective but also ethical, fair, and equitable, ultimately fostering benefits for both patients and healthcare providers.

This review paper is organized into distinct sections that systematically address the integration, impact, and limitations of large language models (LLMs) in healthcare:

- Section **2** provides a foundational understanding of LLMs, covering their key architectures such as Transform- ers, foundational models, and multi-modal capabilities.
- In section **3**, the focus shifts to the application of LLMs in healthcare, discussing their use cases and the metrics for assessing their performance within clinical settings.
- Section **4** critically examines the challenges associated with LLMs in healthcare, including issues related to explainability, security, bias, and ethical considerations.
- The paper concludes by summarizing the findings, highlighting the transformative potential of LLMs while acknowledging the need for careful implementation to navigate their limitations and ethical implications.

1. # <a name=" review of large language models "></a>**Review of Large Language Models**
Large language models have emerged as a notable advancement in the field of natural language processing (NLP) and have attracted considerable interest in recent times [[16](#_bookmark24), [10](#_bookmark18)]. These models exhibit notable attributes such as their considerable number of parameters, pre-training on vast collections of textual data, and fine-tuning for specific downstream objectives [[17](#_bookmark25), [18](#_bookmark26), [13](#_bookmark21)]. By leveraging these key characteristics, large language models demonstrate exceptional performance across a wide range of NLP tasks. This section presents a comprehensive discussion of the concept, architecture, and pioneering examples of large language models. Furthermore, we explore the pre-training methodology and the significance of transfer learning in facilitating these models to achieve exceptional performance across diverse tasks [\[19\].](#_bookmark27)

Large Language models, built upon the Transformer architecture, have been specifically engineered to enhance the efficiency of natural language data processing in comparison to earlier iterations. The Transformer architecture, as proposed by [[20](#_bookmark28)], utilizes a self-attention mechanism to capture the contextual relationships between words in a sentence.


![](Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.007.png)


This mechanism facilitates the model’s ability to assign varying degrees of significance to distinct words during the prediction process, rendering it especially suitable for handling long-range dependencies in language.

The key aspects of large language models encompass their substantial magnitude [[21](#_bookmark29), [22](#_bookmark30)], pre-training on vast text corpora [[23](#_bookmark31), [13](#_bookmark21)], and subsequent fine-tuning tailored towards specific tasks [[24](#_bookmark32)]. These models possess a substantial number of parameters, ranging from hundreds of millions to billions, which allows them to effectively capture intricate patterns and nuances within language. Pre-training is commonly conducted on diverse datasets devoid of task-specific annotations, enabling the model to acquire knowledge from a broad spectrum of linguistic instances and develop a comprehensive grasp of language. Following pre-training, the model undergoes a further fine-tuning process using smaller datasets that are appropriate to the task at hand. This allows the model to successfully adapt to and perform well on specific natural language processing (NLP) tasks.

The progression of natural language processing (NLP) has been characterized by a series of significant advancements. At the outset, recurrent neural networks (RNNs) facilitated the retention of context in natural language processing (NLP) tasks. Nevertheless, recurrent neural networks (RNNs) were found to have several shortcomings when it comes to effectively capturing long-range dependencies. The advent of Transformers has had a transformative impact by effectively addressing the challenge of capturing distant word relationships. Subsequently, large language models like Llama 2 [[13](#_bookmark21)], GPT-4 [[11](#_bookmark19)] emerged, powered by extensive training data, significantly advancing NLP capabilities in understanding and generating human-like text. This progression signifies a continuous cycle of innovation, with each stage building upon the strengths and limitations of its predecessor. In the subsequent section, we delineate significant phases of development within the continuum of progress in the landscape of natural language processing (NLP).

In the domain of healthcare, specialized adaptations of BERT, namely BioBERT [[14](#_bookmark22)] and ClinicalBERT [[15](#_bookmark23)], were introduced to address a variety of challenges in comprehending clinical language. GPT-3 (Generative Pre-trained Transformer 3), developed by OpenAI, is one of the largest language models to date, with 175 billion parameters [[10](#_bookmark18)]. Recently, OpenAI introduced the GPT-3.5 and its successor, GPT-4 (OpenAI, 2023) [[11](#_bookmark19)], alongside Google AI’s Bard, both of which have emerged as cutting-edge Large Language Models (LLMs), displaying remarkable capabilities across diverse applications, including healthcare and medicine [\[6\].](#_bookmark14)

1. ## <a name="transformers"></a>**Transformers**
The Transformers architecture, introduced in "Attention is All You Need," [[20](#_bookmark28)] has revolutionized natural language processing. The primary novelty of this model is its utilization of the self-attention mechanism, which allows for the assessment of the importance of input tokens by considering their relevance to the given task. In this setup, multiple attention heads work in parallel, allowing the model to focus on various aspects of the input whereas positional encoding conveys relative token positions. Given an input sequence *X* of length *N* , the self-attention mechanism [[25](#_bookmark33), [26](#_bookmark34), [27](#_bookmark35)] computes attention scores *A*(*i, j*) between all token pairs (*i, j*). Three learned matrices, Query (*Q*), Key (*K*), and Value (*V* ), are obtained by linear projections of *X*.

<i>QK<sup>T</sup></i>



![](Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.008.png)![](Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.009.png)*Attention*(*Q, K, V* ) = *softmax*( *√d*  )*V*

Here, <i>d<sub>k</sub></i> represents the dimension of key vectors. The softmax function normalizes scores. The output for each token is then computed as a weighted sum of value vectors for all tokens j. Multi-Head Attention extends this mechanism by computing multiple attention sets in parallel, concatenated and linearly transformed to form the final output.

Transformers consist of stacked encoder-decoder blocks, adapting to diverse tasks. The training occurs via unsupervised or semi-supervised learning on vast text corpora, using gradient-based optimization. Transformers have become foundational in natural language processing due to their capacity to handle sequential data, capture long-range dependencies, and adapt to various tasks with minimal fine-tuning. They extend beyond text, finding applications in healthcare, recommendation systems, image generation, and other domains.

1. ## <a name="large foundational models"></a>**Large Foundational Models**
The advent of Large Foundational Models, exemplified by GPT-3 (Brown et al., 2020) [[10](#_bookmark18)] and Stable Diffusion (Rombach et al., 2022) [[28](#_bookmark36)], ushers in a transformative era in the field of machine learning and generative artificial intelligence. Researchers have introduced the term "foundation model" to delineate machine learning models that undergo training on extensive, diverse, and unlabeled datasets, endowing them with the ability to adeptly tackle a broad spectrum of general tasks. These encompass tasks related to language comprehension, text and image generation, and natural language dialogue.



![](Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.010.jpeg)

Figure 1: <a name="_bookmark0"></a>Scale of Medical Language Models: A Size Comparison

Large foundational models are massive AI architectures trained on extensive quantities of unlabeled data, predominantly employing self-supervised learning methods. This approach to training yields models of exceptional versatility, enabling them to excel across a wide spectrum of tasks, ranging from image classification and natural language processing to question-answering, consistently delivering outstanding levels of accuracy.

These models particularly shine in tasks demanding generative capabilities and human interaction, including the creation of marketing content or intricate artwork based on minimal prompts. Nevertheless, adapting and integrating these models into enterprise applications may present specific challenges [\[29\].](#_bookmark37)

1. ## <a name="multi-modal language models"></a>**Multi-modal Language Models**
A Multi-Modal Large Language Model (MLLM) represents a groundbreaking advancement in the fields of artificial intelligence (AI) and natural language processing (NLP). In contrast to conventional language models focused solely on textual data, MLLMs possess the unique ability to process and generate content across multiple modalities, including text, images, audio, and video. This novel approach significantly expands the capabilities of AI applications, allowing machines not only to comprehend and generate text but also to interpret and integrate information from various sensory inputs. The integration of multiple modalities enables MLLMs to bridge the gap between human communication and machine understanding, making them versatile tools with the potential to transform diverse fields. This theoretical introduction highlights the transformative potential of MLLMs and their central role in pushing the boundaries of artificial intelligence, affecting areas such as image and speech recognition, content generation, and interactive AI applications [\[30\].](#_bookmark38)

Multi-modal large language models (MLLMs) are designed to process and integrate information from multiple data sources, such as text, images, and audio, to perform a variety of tasks. These models leverage deep learning techniques to understand and generate content across different modalities, enhancing their applicability in real-world scenarios. For instance, Visual ChatGPT combines text and visual inputs to address complex queries [[31](#_bookmark39)], while systems like BLIP-2 utilize a Qformer to integrate visual features with textual data for enhanced image-text interactions [[32](#_bookmark40)]. MLLMs are particularly effective in tasks like visual question answering (VQA), where they can interpret and respond to queries based on visual content. The integration of modalities allows these models to offer more comprehensive responses and handle a broader range of interactions than single-modality models. The iterative training processes, often involving stages of freezing certain components while fine-tuning others, enable these models to maintain robust language capabilities while adapting to new modalities and tasks.



![](Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.011.png)

Figure 2: <a name="_bookmark1"></a>Schematic Representation of a Standard Multimodal Large Language Model (MLLM) Architecture


Figure [2](#_bookmark1) displays a typical MLLM architecture, comprising an encoder <i>E<sub>M</sub></i> , a connector <i>C</i>, and a Large Language Model (LLM). Additionally, a generator <i>G</i> can be integrated with the LLM to produce outputs beyond text, such as other modalities. The encoder processes inputs like images, audio, or videos into features, which the connector refines to enhance the LLM’s comprehension capabilities. Connectors in these systems come in three main varieties: projection-based, query-based, and fusion-based. The first two types utilize token-level fusion, converting features into tokens that are combined with text tokens, whereas the fusion-based connector performs a feature-level fusion directly within the LLM [\[30\].](#_bookmark38)

Recently, the integration of the Mixture of Experts (MoE) architecture into multi-modal large language models (MLLMs) has significantly advanced their capabilities. This approach employs multiple specialized sub-models, each fine-tuned for specific types of data or tasks such as image recognition or language processing. By selectively activating the most relevant experts based on the input and task, MoE allows MLLMs to dynamically adapt to the demands of multimodal data integration. This enhances the precision of the model in handling complex multimodal interactions and optimizes computational resources. Models like MoVA [[33](#_bookmark41)] and MoE-LLaVA [[34](#_bookmark42)] leverage MoE strategies effectively, improving performance while maintaining manageable computational costs during both training and inference phases. The adaptability and efficiency of MoE within MLLMs thus contribute significantly to their scalability and efficacy in real-world applications across varied tasks and data types [\[35\].](#_bookmark43)

1. # <a name="large language models in healthcare and "></a>**Large Language Models in Healthcare and Medical Domain**

Language models have become a revolutionary force in the constantly changing world of healthcare and medicine, revolutionising how medical researchers and practitioners engage with data, patients, and huge corpus of medical knowledge [[36](#_bookmark44)]. The use of language models in the medical field has undergone a significant metamorphosis, from the early days of simple rule-based systems, feature extraction, and keyword matching to the arrival of cutting-edge technologies like Transformers, and Large Language Models (LLMs) such as GPT-v4 [[11](#_bookmark19)]. These language models have overcome the constraints of conventional methods, enabling more complex natural language generation and interpretation.

Several pioneering large language models have significantly influenced the landscape of NLP. The emergence of the Transformer architecture [[20](#_bookmark28)] marked a significant milestone in the realm of natural language processing, leading to the emergence of expansive pre-trained language models like the BERT [\[37\]](#_bookmark45) and RoBERTa [\[38\].](#_bookmark46)

BERT (Bidirectional Encoder Representations from Transformers), introduced by Devlin et al. (2018) [[37](#_bookmark45)], revolution- ized NLP by pre-training a deep bidirectional model on a large corpus and outperforming previous models on various tasks. RoBERTa (A Robustly Optimized BERT Pretraining Approach) by Liu et al. (2019) [[38](#_bookmark46)] demonstrated that further pre-training improvements and optimization could significantly enhance the performance of BERT.

In this section, we will first talk about the current large language models specifically for medical applications, in section [3.1.](#_bookmark3) Then, in section [3.2](#_bookmark4) we will talk about the use cases of various LLMs that designed mainly for patients, experts, and medical materials.



Table 1: <a name="_bookmark2"></a>Summary of Large Language Models in the Healthcare Space

|Method|Year|Task|Institution|<p>Source</p><p>Code</p>|
| :- | :-: | :- | :- | :- |
|BioMistral [\[39\]](#_bookmark47)|2024|<p>Medical Question Answer-</p><p>ing</p>|<p>Avignon	Université,</p><p>Nantes Université</p>|[model](https://huggingface.co/BioMistral/BioMistral-7B)|
|<p>Med-PaLM	2</p><p>[\[40\]](#_bookmark48)</p>|2023|<p>Medical Question Answer-</p><p>ing</p>|<p>Google Research, Deep-</p><p>Mind</p>||
|<p>Radiology-</p><p>Llama2 [\[41\]](#_bookmark49)</p>|2023|Radiology|University of Georgia||
|DeID-GPT [[42](#_bookmark50)]|2023|De-identification|University of Georgia|[code](https://github.com/yhydhx/ChatGPT-API)|
|<p>Med-HALT</p><p>[\[43\]](#_bookmark51)</p>|2023|Hallucination test|Saama AI Research|[code](https://github.com/medhalt/medhalt)|
|ChatCAD [\[44\]](#_bookmark52)|2023|Computer-aided diagnosis|ShanghaiTech University|[code](https://github.com/zhaozh10/ChatCAD)|
|BioGPT [\[45\]](#_bookmark53)|2023|<p>Classification, relation ex-</p><p>traction, question answer- ing, etc.</p>|Microsoft Research|[code](https://github.com/microsoft/BioGPT)|
|GatorTron [\[46\]](#_bookmark54)|2022|<p>Semantic textual similarity,</p><p>natural language inference, and medical question an- swering</p>|University of Florida|[code](https://github.com/uf-hobi-informatics-lab/GatorTron)|
|BioMedLM|2022|<p>Biomedical  question  an-</p><p>swering</p>|<p>Stanford  CRFM,  Mo-</p><p>saicML</p>|[code](https://github.com/stanford-crfm/BioMedLM)|
|BioBART [\[47\]](#_bookmark55)|2022|<p>Dialogue, summarization,</p><p>entity linking, and NER</p>|<p>Tsinghua University, In-</p><p>ternational Digital Econ- omy Academy</p>|[code](https://github.com/GanjinZero/BioBART)|
|ClinicalT5 [\[48\]](#_bookmark56)|2022|Classification, NER|<p>University  of  Oregon,</p><p>Baidu Research</p>|[model](https://huggingface.co/xyla/Clinical-T5-Large)|
|KeBioLM [\[49\]](#_bookmark57)|2021|<p>Biomedical	pre-training,</p><p>NER, and relation extrac- tion</p>|<p>Tsinghua University, Al-</p><p>ibaba Group</p>|[code](https://github.com/GanjinZero/KeBioLM)|
|CRNN [\[50\]](#_bookmark58)|2017|Relation classification|<p>Indian Institute of Tech-</p><p>nology</p>|[code](https://github.com/desh2608/crnn-relation-classification)|
|<p>LSTM	RNN</p><p>[\[51\]](#_bookmark59)</p>|2017|Named entity recognition|Wuhan University|[code](https://github.com/lvchen1989/BNER)|

1. ## <a name="large language models for medical and he"></a><a name="_bookmark3"></a>**Large Language Models for Medical and Healthcare Applications**
Figure [1](#_bookmark0) provides a comprehensive overview of the progression in biomedical language model (LM) development from 2019 to 2023, emphasizing a logarithmic growth in model complexity and parameter count. It describes the evolutionary trajectories of various domain-specific adaptations of prominent models such as BioBERT, and GPT-2, along with the inception of more advanced systems like MedPaLM. The sizes of the illustrated models are proportional to their parameter volumes, showcasing a consistent trend towards larger, more capable models. This is culminated in the emergence of Large Language Models (LLMs) by 2023, which signifies a pivotal shift towards architectures with substantially heightened computational requirements and potential performance in biomedical text analysis and generation tasks.

On the other hand, table [1](#_bookmark2) provides an insightful overview of leading large language models within the healthcare domain. Recently, "BioMistral" was published as a a collection of open-source pre-trained large language models for medical domains. In 2023, "Med-PaLM 2" and "Radiology-Llama2" emerged as key players, addressing medical question answering and radiology tasks, respectively. The "DeID-GPT" model extends its capabilities to de-identification, while "Med-HALT" specializes in hallucination testing. Simultaneously, "ChatCAD" offers valuable support in the realm of computer-aided diagnosis. "BioGPT" showcases versatility by handling classification, relation extraction, and question answering. "GatorTron" excels in semantic textual similarity and medical question answering, whereas "BioMedLM" narrows its focus to biomedical question answering. "BioBART" demonstrates prowess in dialogue, summarization, entity linking, and NER. "ClinicalT5" tackles classification and NER, while "KeBioLM" specializes in biomedical pre-training, NER, and relation extraction. Before the advent of language models or transformers, convolutional and recurrent neural networks represented the state of the art in the field. These models collectively represent remarkable strides in healthcare NLP, providing accessible source code or models for further exploration and practical application.



![](Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.012.jpeg)

Figure 3: Applications of Large Language Models in Healthcare

1. ## <a name="use cases of large language models in he"></a><a name="_bookmark4"></a>**Use Cases of Large Language Models in Healthcare**
In recent years, the emergence of large language models has catalyzed a transformative shift in the healthcare landscape, offering unprecedented opportunities for innovation and advancement. The capability of comprehending and generating text that resembles that of humans has demonstrated remarkable potential across a wide range of healthcare applications [\[52\].](#_bookmark60) The applications of large language models in the healthcare sector are experiencing rapid growth. These models are being utilized for clinical decision support, medical record analysis, patient engagement, health information dissemination, etc. Their implementation holds the prospect to improve diagnostic accuracy, streamline administrative procedures, and ultimately enhance the efficiency, personalization, and comprehensiveness of healthcare delivery. This section delves into a comprehensive exploration of the multifaceted applications of large language models in healthcare, shedding light on their profound implications these applications bear on the trajectory of medical practices and the eventual outcomes experienced by patients.

0. **Medical Diagnosis:** Certain clinical procedures may depend on the use of data analysis, clinical research, and recommendations [[53](#_bookmark61), [54](#_bookmark62)]. LLMs may potentially contribute to medical diagnosis by conducting analyses on patient symptoms, medical records, and pertinent data, potentially aiding in the identification of potential illnesses or conditions with a certain degree of accuracy. Large language models have the potential to contribute to several aspects such as clinical decision assistance, clinical trial recruiting, clinical data administration, research support, patient education, and other related areas [[55](#_bookmark63), [56](#_bookmark64)]. Corroborating this perspective, authors introduce a methodology that utilizes transformer models, namely BERT, RoBERTa, and DistilBERT, for the purpose of predicting COVID-19 diagnosis based on textual descriptions of acute alterations in chemosensation [[57](#_bookmark65)]. Similarly, a number of alternative investigations have been undertaken within the literature, proposing strategies using large language models for the diagnosis of Alzheimer’s disease [[58](#_bookmark66)] and dementia [[59](#_bookmark67)]. Fur- thermore, a corpus of literature has emerged, advocating the integration of large language model chatbots to cater to analogous objective [\[60,](#_bookmark68) [61,](#_bookmark69) [62,](#_bookmark70) [63\].](#_bookmark71)
0. **Patient Care:** Large Language Models have emerged as transformative tools with the capacity to significantly enhance the realm of patient care [[64](#_bookmark72)]. Through the provision of personalised recommendations [[65](#_bookmark73)], cus- tomised treatment strategies, and continual monitoring of patients’ advancements throughout their medical journeys [[66](#_bookmark74)], LLMs offer the promise of revolutionizing healthcare delivery. By harnessing the capabilities of LLMs, healthcare providers can ensure a more personalized and patient-centric approach to care. This



technology enables the delivery of precise and well-informed medical guidance [[67](#_bookmark75)], aligning interventions with patients’ distinct requirements and circumstances.

The effective use of LLMs within clinical practise not only enhances patient outcomes but also enables healthcare professionals to make data-driven decisions, leading to enhanced patient care. As LLMs continue to advance, the potential for augmenting patient care through personalized recommendations and ongoing monitoring remains a promising trajectory in modern medicine [[68](#_bookmark76)]. In essence, LLMs represent a pivotal leap forward, holding the capacity to reshape the landscape of patient care by fostering precision, adaptability, and patient-centeredness [\[69\].](#_bookmark77)

0. **Clinical Decision Support**: Language models (LMs) have evolved into crucial decision support tools for healthcare professionals. By analyzing extensive medical data, LMs can provide evidence-based recommenda- tions, enhancing diagnostic accuracy, treatment selection, and overall patient care. This fusion of artificial intelligence with healthcare expertise holds immense promise for improved medical decision-making. A body of existing research has illuminated promising prospects for the application of language models within clinical decision support, particularly within the domains of radiology [\[70\],](#_bookmark78) oncology [\[71\]](#_bookmark79) and dermatology [\[72\].](#_bookmark80)
0. **Medical Literature Analysis**: Large language models (LLMs) exhibit remarkable efficiency in comprehen- sively reviewing and succinctly summarizing extensive volumes of medical literature. This capability aids both researchers and clinicians in maintaining topicality with cutting-edge developments and evidence-based methodologies, ultimately fostering informed and optimized healthcare practices. In a fast-evolving field like healthcare, the ability to maintain currency with the latest advancements is paramount, and LLMs can play a pivotal role in ensuring that healthcare remains at the forefront of innovation and evidence-based care delivery [\[73,](#_bookmark81) [74\].](#_bookmark82)
0. **Drug Discovery**: Large Language Models, have a significant impact in facilitating drug discovery through their capacity to scrutinize intricate molecular structures, discern promising compounds with therapeutic potential, and forecast the efficacy and safety profiles of these candidates [[75](#_bookmark83), [76](#_bookmark84)]. Chemical language models have exhibited notable achievements in the domain of de novo drug design [[77](#_bookmark85)]. In this corresponding study, authors explore the utilization of pre-trained biochemical language models to initialize targeted molecule generation models, comparing one-stage and two-stage warm start strategies, as well as evaluating compound generation using beam search and sampling, ultimately demonstrating that warm-started models outperform baseline models and the one-stage strategy exhibits superior generalization in terms of docking evaluation and benchmark metrics, while beam search proves more effective than sampling for assessing compound quality [\[78\].](#_bookmark86)
0. **Virtual Medical Assistants and Health Chatbots**: LLMs may also serve as the underlying intelligence for health chatbots, revolutionizing the healthcare landscape by delivering continuous and personalized health- related support. These chatbots can offer medical advice, monitor health conditions, and even extend their services to encompass mental health support, a particularly pertinent aspect of healthcare given the growing awareness of mental well-being [\[63,](#_bookmark71) [60\].](#_bookmark68)
0. **Radiology and Imaging:** Multi-modal visual-language models, through their integration of visual and textual data, hold significant promise for augmenting medical imaging analysis. Radiologists can benefit from these models as they facilitate the early identification of abnormalities in medical images and contribute to the generation of more precise and comprehensive diagnostic interpretations, ultimately advancing the accuracy and efficiency of diagnostic processes in the field of medical imaging [\[79,](#_bookmark87) [70,](#_bookmark78) [80,](#_bookmark88) [81,](#_bookmark89) [82,](#_bookmark90) [83,](#_bookmark91) [84\].](#_bookmark92)
0. **Automated Medical Report Synthesis from Imaging Data:** Automated medical report generation from images is crucial for streamlining the time-consuming and error-prone task faced by pathologists and radiol- ogists. This emerging field at the intersection of healthcare and artificial intelligence (AI) aims to alleviate the burden on experienced medical practitioners and enhance the accuracy of less-experienced ones. The integration of AI with medical imaging facilitates the automatic drafting of reports, encompassing abnormal findings, relevant normal observations, and patient history. Early efforts employed data-driven neural networks, combining convolutional and recurrent models for single-sentence reports, but limitations arose in capturing the complexity of real medical scenarios [[5](#_bookmark13)]. Recent advances leverage large language models (LLMs) such as ChatCAD [[70](#_bookmark78)], enabling more sophisticated applications. ChatCAD enhances medical-image Computer-Aided Diagnosis networks, yielding significant improvements in report generation. ChatCAD+ further addresses writing style mismatches, ensuring universality and reliability across diverse medical domains, incorporating a template retrieval system for consistency with human expertise [[44](#_bookmark52)]. In [[85](#_bookmark93)], authors use pre-trained language model (PLM) and in-context learning (ICL) to generate clinical note from doctor patient conversation. These integrated systems signify a pivotal advancement in automating medical report generation through the strategic utilization of LLMs.



Table 2: <a name="_bookmark5"></a>Summary of Recent XIAI Methods for LLMs in Healthcare

|**Method**|**Year**|**Task**|**XIAI Attributes**|<p>**XIAI	Evaluation**</p><p>**Metric**</p>|
| :- | :-: | :- | :- | :- |
|<p>MentaLLaMA</p><p>[\[code\]](https://github.com/SteveKGYang/MentalLLaMA) [\[94\]](#_bookmark102)</p>|2024|Mental health analysis|<p>Prompt-based  (ChatGPT  w/  task-</p><p>specific instructions)</p>|<p>BART-score, Human</p><p>Eval</p>|
|<p>ArgMed-</p><p>Agents [\[93\]](#_bookmark101)</p>|2024|Clinical decision reasoning|<p>Prompt-based (Self-argumentation iter-</p><p>ations + symbolic solver)</p>|<p>Pred. accuracy with</p><p>LLM evaluator</p>|
|<p>Diagnostic rea-</p><p>soning prompts [\[95\]](#_bookmark103)</p>|2024|<p>Medical Question Answering</p><p>(MedQA)</p>|<p>Prompt-based (Bayesian, differential di-</p><p>agnosis, analytical, and intuitive reason- ing)</p>|<p>Expert	Evaluation,</p><p>Inter-rater agreement</p>|
|SkinGEN [\[96\]](#_bookmark104)|2024|Dermatological diagnosis|<p>Visual explanations (Stable Diffusion),</p><p>interactive framework</p>|<p>Perceived explainabil-</p><p>ity ratings</p>|
|<p>DR.  KNOWS</p><p>[\[91\]](#_bookmark99)</p>|2023|Automated diagnosis generation|<p>Knowledge Graph (explainable diagnos-</p><p>tic pathway)</p>|-|
|<p>Human-AI Col-</p><p>laboration [\[97\]](#_bookmark105)</p>|2023|Clinical decision making|<p>Salient features, counterfactual explana-</p><p>tions</p>|<p>Agreement	Level,</p><p>Usability Question- naires</p>|
|ChatGPT [\[92\]](#_bookmark100)|2023|Mental health analysis|<p>Prompt-based  (emotional  cues  and</p><p>expert-written few-shot examples)</p>|<p>BART-score, Human</p><p>Eval</p>|
|CHiLL [\[98\]](#_bookmark106)|2023|<p>Clinical predictive tasks, Chest</p><p>X-ray report classification</p>|Interpretable features, linear models|<p>Expert	Evaluation,</p><p>Clinical Judgement Alignment</p>|
|Trap-VQA [\[99\]](#_bookmark107)|2022|<p>Pathology Visual Question An-</p><p>swering (PathVQA)</p>|<p>Grad-CAM, SHapley Additive exPlana-</p><p>tions</p>|<p>Qualitative  Evalua-</p><p>tion</p>|
|<p>Vision	Trans-</p><p>former [\[100\]](#_bookmark108)</p>|2021|Covid-19 diagnosis|Saliency maps|Visualisation|
|<p>ClinicalBERT</p><p>[\[code\]](https://github.com/kexinhuang12345/clinicalBERT) [\[15\]](#_bookmark23)</p>|2019|Predicting hospital readmission|Attention weights|Visualisation|



1. ## <a name="explainable ai methods for interpreting "></a>**Explainable AI Methods for Interpreting Healthcare LLMs**

Large Language Models (LLMs) have significantly advanced the healthcare domain, enhancing tasks such as med- ical diagnosis and patient monitoring. However, the complexity of these models necessitates interpretability for reliable decision-making [[86](#_bookmark94)]. This section discusses "eXplainable and Interpretable Artificial Intelligence" (XIAI) and examines recent XIAI methods by their functionality and scope. Despite challenges, such as the difficulty in quantifying interpretability and the lack of standardized evaluation metrics, opportunities exist in integrating XIAI to add interpretability for LLMs in healthcare. Notable XIAI methods include SHAP [[87](#_bookmark95)], which quantifies feature contributions, LIME [[88](#_bookmark96), [89](#_bookmark97)], which generates interpretable models through input perturbations, t-SNE for visualizing high-dimensional data [[90](#_bookmark98)], attention mechanisms that highlight key features [[15](#_bookmark23)], and knowledge graphs that structure contextual relationships [\[91\],](#_bookmark99) all of which provide crucial insights into model decision-making processes.

Existing research delves into explainability for LLMs in the healthcare domain. For instance, Yang et al. (2023) [[92](#_bookmark100)] investigate different prompting strategies using emotional cues and expert-written examples for mental health analysis with LLMs. This study shows that models like ChatGPT can generate near-human-level explanations, enhancing interpretability and performance. Additionally, ArgMedAgents (Hong et al., 2024) [[93](#_bookmark101)] is a multi-agent framework designed for explainable clinical decision reasoning through interaction, utilizing the Argumentation Scheme for Clinical Discussion and a symbolic solver to provide clear decision explanations. Furthermore, Gao et al. (2023) propose enhancing LLM explainability for automated diagnosis by integrating a medical knowledge graph (KG) from the Unified Medical Language System (UMLS), using the DR.KNOWS model to interpret complex medical concepts. Their experiments with real-world hospital data demonstrate a transparent diagnostic pathway. Similarly, TraP-VQA [[91](#_bookmark99)], a novel vision-language transformer for Pathology Visual Question Answering (PathVQA), employs Grad-CAM and SHAP methods to offer visual and textual explanations, ensuring transparency and fostering user trust.

We have compiled a list in table [2,](#_bookmark5) detailing XIAI attributes, summarizing recent research works focused on explainability methods for LLMs in the healthcare domain. This table includes evaluations of various models, highlighting their unique contributions to enhancing interpretability and reliability in medical applications. Each entry outlines the task, method, XAI attributes, and evaluation metrics, offering a clear overview of the advancements and effectiveness of XIAI techniques in improving decision-making processes in healthcare.



1. ## <a name="future trajectories of large language mo"></a>**Future Trajectories of Large Language Models in Healthcare**
As large language models (LLMs) continue to integrate into the healthcare sector, future developments promise to revolutionize patient care and medical research. A particularly promising avenue involves enhancing LLMs’ capabilities to interpret and generate not only textual but also biomolecular data [[101](#_bookmark109)]. This advancement could significantly improve applications in genomics and personalized medicine, enabling these models to predict individual responses to treatments based on genetic profiles, thereby advancing the precision of medical interventions. Furthermore, incorporating adaptive learning capabilities in real-time could transform LLMs into dynamic aids during surgical procedures or emergencies, where they might analyze data from medical devices on-the-fly [\[102\]](#_bookmark110) to offer critical decision support.

Another innovative trajectory for LLMs in healthcare is the development of federated learning systems [[103](#_bookmark111)]. Such systems could facilitate the secure, privacy-preserving propagation of medical knowledge across institutions, improving model robustness and applicability across varied demographic groups without direct data sharing. This approach will not only enhance the privacy and security of patient data but will also enable a collective intelligence that could lead to more generalized healthcare solutions.

The potential of large language models (LLMs) in healthcare extends into the realms of explainable medical AI [[104](#_bookmark112)] and the utilization of multi-modal models incorporating sensor data. By integrating LLMs with wearable technologies [\[105\],](#_bookmark113) these advanced models can serve as continuous health monitors in non-clinical settings.

To further advance explainable medical AI, LLMs can be instrumental in deciphering the complexities of medical conditions and treatment outcomes. By processing and interpreting multi-modal data, including sensor readings, these models can contribute to a deeper understanding of patient health on a granular level. This may aid in the development of precise, targeted therapies, improving patient outcomes and enhancing the transparency of medical decisions.

Large Language Models (LLMs) are poised to revolutionize the healthcare domain by enhancing diagnostic accuracy, personalizing treatment plans, and optimizing operational efficiencies. By integrating LLMs into electronic health record systems, healthcare providers can more accurately diagnose conditions through natural language processing techniques that analyze clinical notes and patient histories. Moreover, LLMs assist in generating personalized treatment recommendations by analyzing vast datasets that include genetic information, clinical outcomes, and patient preferences. Furthermore, these models streamline administrative tasks by automating documentation, coding, and billing processes, thus reducing operational costs and allowing medical staff to focus more on patient care. As generative AI advances, its transformative impact on the healthcare sector is becoming increasingly significant. This technology is poised to revolutionize areas such as clinical trials, personalized medicine, and drug discovery. Additionally, its applications extend to enhancing natural language processing and understanding, improving medical imaging, and supporting virtual assistants in patient care. Generative AI also plays a crucial role in illness detection and screening, facilitating more accurate diagnostics. Moreover, it is being integrated into medical conversation tasks, voice generation, video generation, and image synthesis and manipulation within healthcare settings [[106](#_bookmark114)]. These innovations are not only improving the efficiency of medical services but are also paving the way for new methods of patient interaction and treatment planning. As these applications continue to mature, LLMs will become integral in transforming healthcare services into more efficient, accurate, and personalized systems.

1. ## <a name="performance evaluation and benchmarks"></a>**Performance Evaluation and Benchmarks**
The medicine and healthcare industries largely acknowledge the potential of artificial intelligence (AI) to drive substantial progress in the delivery of healthcare. However, empirical evaluations have demonstrated that numerous artificial intelligence (AI) systems do not successfully achieve their desired translation goals, primarily because of intrinsic deficiencies that become evident only after implementation [\[107,](#_bookmark115) [108\].](#_bookmark116) In order to optimize the utilization of language models (LLMs) within healthcare settings, it is imperative to develop evaluation frameworks that possess the capacity to thoroughly evaluate their safety and quality. It is important to note that certain highly effective models, such as ChatGPT and PaLM 2 [[109](#_bookmark117)], are now not publicly available. The absence of accessibility gives rise to notable problems pertaining to transparency, which is a crucial factor in the medical domain and hinders the capacity to thoroughly examine the structure and results of the model. Consequently, this impedes endeavors to recognize and address biases and hallucinations. Thorough research is necessary to understand the specific performance characteristics and ramifications of utilizing publicly accessible, pre-trained language models in addressing the challenges in the healthcare and medical domains. Language models that have been pre-trained using medical data also encounter comparable difficulties. Therefore, the careful choice and implementation of suitable performance metrics to evaluate the language model assume great significance.

In table [4,](#_bookmark8) we present a comprehensive catalog of performance metrics, including but not limited to the F1 score, BLEU, GLUE, and ROGUE, which constitute the standard evaluative criteria employed for the rigorous assessment of large language models operating within the healthcare and medical domain. This compendium of metrics serves as a



![](Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.013.jpeg)
||||||
| :- | :-: | :- | :- | :-: |
||||||
||||||
||||||
||||||
||||||
||||||
||||||
||||||
||||||
||||||
||||||
||||||


![](Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.014.png)Figure 4: <a name="_bookmark7"></a>Comparative Performance of Healthcare LLMs Table 3: <a name="_bookmark6"></a>LLM Performance Benchmark












valuable reference, encapsulating the quantitative and qualitative measures utilized to gauge the efficacy, proficiency, and suitability of these models in diverse healthcare applications [\[108\].](#_bookmark116)

1. ## <a name="quantitative performance comparison of l"></a>**Quantitative Performance Comparison of LLMs in Healthcare Domain**
Recent advancements in language models have been benchmarked against diverse datasets to evaluate their capabilities across various domains. One such comprehensive benchmark is the MMLU (Massive Multitask Language Under- standing) [[110](#_bookmark118)], designed to assess the understanding and problem-solving abilities of language models. The MMLU comprises 57 tasks spanning topics such as elementary mathematics, US history, computer science, and law, requiring models to demonstrate a broad knowledge base and problem-solving skills. This benchmark provides a standardized method to test and compare various language models, including OpenAI GPT-4o, Mistral 7b, Google Gemini, and Anthropic Claude 3, among others.



The HumanEval benchmark is used to measure the functional correctness of code generated by LLMs from docstrings. This benchmark evaluates models based on their ability to generate code that passes provided unit tests, using the pass@k metric. If any of the ’k’ solutions generated by the model pass all unit tests, the model is considered successful in solving the problem [[111](#_bookmark119)]. Table [3](#_bookmark6) provides a concise summary of the performance of various LLMs on the MMLU and HumanEval (Coding) datasets [\[112\].](#_bookmark120)

In the healthcare domain, a variety of LLMs have been developed and evaluated on specific datasets such as MedQA, MedNLI [[113](#_bookmark121)], Tox21 [[114](#_bookmark122)], and PubMedQA [[115](#_bookmark123)]. The GPT-4 (2024) model stands out in the MedQA dataset with an impressive accuracy of 93.06%, significantly outperforming other models like Med-PaLM 2 (CoT + SC) (2023), which achieves 83.7%, and Meerkat-7B (Ensemble) (2024), with 74.3%. In the MedNLI dataset, BioELECTRA-Base (2021) achieves the highest accuracy of 86.34%, closely followed by CharacterBERT (base, medical) (2020) at 84.95%. The Tox21 dataset highlights elEmBERT-V1 (2023) with an outstanding AUC of 0.961, making it the most effective in predicting chemical properties and toxicity. For the PubMedQA dataset, Meditron-70B (CoT + SC) (2023) and BioGPT-Large (1.5B) (2023) exhibit strong performance with accuracies of 81.6% and 81.0%, respectively [[116](#_bookmark124)]. These findings underscore the variability in performance across different healthcare tasks, emphasizing the need for careful selection of models based on specific application requirements [[117](#_bookmark125)]. Figure [4](#_bookmark7) presents a comparative performance analysis of various healthcare LLMs, highlighting their accuracy and AUC metrics across different datasets including MedQA, MedNLI, Tox21, and PubMedQA.

1. # <a name="limitations and open challenges"></a>**Limitations and Open Challenges**
The integration of large language models (LLMs) in healthcare presents complex challenges, including the need for explainability in model decision-making, robust security and privacy measures to protect sensitive patient data, addressing biases and ensuring fairness in medical AI applications, mitigating the issue of hallucinations where models generate erroneous information, and establishing clear legal frameworks for the responsible use of LLMs in healthcare, all of which demand careful scrutiny and resolution to harness the full potential of these models for improving healthcare outcomes while upholding ethical and legal standards.

1. ## <a name="model explainability and transparency"></a>**Model Explainability and Transparency**
Large language models face notable challenges when applied to healthcare. Their recommendations often lack transparency due to their opaque nature, which can hinder acceptance among healthcare professionals who prioritize explainability in medical decision-making. Moreover, the presence of biases in the training data may compromise the accuracy of these models, potentially leading to incorrect diagnoses or treatment recommendations. It is therefore crucial for medical professionals to exercise caution and thoroughly review and validate the recommendations provided by large language models before integrating them into their clinical decision-making processes [[127](#_bookmark135)]. In healthcare, the importance of interpretability and explainability for AI models utilized in medical imaging analysis and clinical risk prediction cannot be overstated. Inadequate transparency and explainability have the potential to undermine trustworthiness and hinder the validation of clinical recommendations. Consequently, effective governance underscores the continuous pursuit of transparency and interpretable frameworks, aiming to augment the decision-making process in the realm of healthcare [[108](#_bookmark116)]. Large language models (LLMs) often function as "blackboxes", rendering it challenging to discern the underlying processes leading to specific conclusions or suggestions. In the healthcare context, where the repercussions of decisions are profound, it becomes imperative for practitioners to grasp the logic behind AI-generated outputs. The persistent endeavor to create models that are more interpretable and transparent remains an enduring challenge within the healthcare domain [\[128,](#_bookmark136) [129,](#_bookmark137) [130\].](#_bookmark138)

1. ## <a name="security and privacy considerations"></a>**Security and Privacy Considerations**
Large Language Models (LLMs) are used in medical research, which necessitates careful consideration of data privacy and security issues. Researchers are entrusted with the duty of managing extremely private patient data while enforcing rigorous compliance with current privacy laws. The use of LLMs in this setting raises concerns about a number of aspects of data processing, including as data protection, the possibility of re-identification, and the moral application of patient data. One notable issue is the inadvertent inclusion of personally identifiable information (PII) within pre-training datasets, which can compromise patient confidentiality. Additionally, LLMs can make privacy-invading inferences by deducing sensitive personal attributes from seemingly innocuous data, potentially violating individual privacy [[131](#_bookmark139)]. Implementing strong measures like data anonymization, safe data storage procedures, and steadfast adherence to ethical standards are essential to addressing these issues. Together, these steps make up crucial safeguards meant to protect research participants’ trust, maintain the integrity of research processes, and protect patient privacy. The importance of these factors is underscored by the necessity of balancing the significant contributions of LLMs



Table 4: <a name="_bookmark8"></a>Evaluation Metrics for Language Models in Healthcare Domain

<table><tr><th colspan="1" valign="top"><b>Eval. Metric</b></th><th colspan="1" valign="top"><b>Description</b></th><th colspan="1" valign="top"><b>References</b></th><th colspan="1" valign="top"><b>Key Highlights</b></th></tr>
<tr><td colspan="1" rowspan="4" valign="top"><p></p><p></p><p>Perplexity</p></td><td colspan="1" rowspan="4" valign="top">Perplexity, a probabilistic metric, quan- tifies the uncertainty in the predictions of a language model. Lower values indi- cate higher prediction accuracy and co- herence.</td><td colspan="1" valign="top">[\[118\]](#_bookmark126)</td><td colspan="1" valign="top">-</td></tr>
<tr><td colspan="1" valign="top">[\[119\]](#_bookmark127)</td><td colspan="1" valign="top">The federated learning model achieved a best perplexity value of <b>3.41</b> for English.</td></tr>
<tr><td colspan="1" valign="top">[\[120\]](#_bookmark128)</td><td colspan="1" valign="top"><p>The Transformer model achieved a test perplexity of</p><p><b>15.6</b> on the PSVG dataset, significantly outperforming the LSTM’s perplexity of <b>20.7</b>.</p></td></tr>
<tr><td colspan="1" valign="top">[\[91\]](#_bookmark99)</td><td colspan="1" valign="top">The lowest perplexity achieved was <b>3.86e-13</b> with manually de- signed prompts.</td></tr>
<tr><td colspan="1" rowspan="2" valign="top">BLEU</td><td colspan="1" rowspan="2" valign="top">The BLEU score assesses the quality of machine translation by comparing it to reference translations.</td><td colspan="1" valign="top">[\[121\]](#_bookmark129)</td><td colspan="1" valign="top">The best BLEU-1 score achieved was <b>13.9</b> by the ClinicalGPT model.</td></tr>
<tr><td colspan="1" valign="top">[\[122\]](#_bookmark130)</td><td colspan="1" valign="top">T-5 (fine-tuned) model achieved the best BLEU-1 score of <b>26.63</b>.</td></tr>
<tr><td colspan="1" rowspan="2" valign="top">GLEU</td><td colspan="1" rowspan="2" valign="top">GLEU score computes mean scores of various n-grams to assess text generation quality.</td><td colspan="1" valign="top">[\[121\]](#_bookmark129)</td><td colspan="1" valign="top">The best GLEU score achieved was <b>2.2</b> by the Bloom-7B model.</td></tr>
<tr><td colspan="1" valign="top">[\[122\]](#_bookmark130)</td><td colspan="1" valign="top">T-5 (fine-tuned) model achieved the best GLEU score of <b>11.38</b>.</td></tr>
<tr><td colspan="1" rowspan="2" valign="top">ROUGE</td><td colspan="1" rowspan="2" valign="top">ROUGE score evaluates summarization and translation by measuring overlap with reference summaries.</td><td colspan="1" valign="top">[\[121\]](#_bookmark129)</td><td colspan="1" valign="top">The best ROGUE-L score achieved was <b>21.3</b> by the Clini- calGPT model.</td></tr>
<tr><td colspan="1" valign="top">[\[122\]](#_bookmark130)</td><td colspan="1" valign="top">T-5 (fine-tuned) model achieved the best ROGUE-L score of <b>24.85</b>.</td></tr>
<tr><td colspan="1" valign="top">Distinct n-grams</td><td colspan="1" valign="top">Measures the diversity of generated re- sponses by counting unique n-grams.</td><td colspan="1" valign="top">[\[122\]](#_bookmark130)</td><td colspan="1" valign="top">On the Huatuo-26M dataset, the fine-tuned T5 model achieved Distinct-1 and Distinct-2 scores of <b>0.51</b> and <b>0.68</b>, respectively.</td></tr>
<tr><td colspan="1" rowspan="4" valign="top"><p></p><p></p><p>F1 Score</p></td><td colspan="1" rowspan="4" valign="top">The F1 score balances precision and re- call, measuring a model’s accuracy in identifying positive instances and mini- mizing false results.</td><td colspan="1" valign="top">[\[123\]](#_bookmark131)</td><td colspan="1" valign="top">The GatorTron-large model achieved the best F1 score of <b>0.9627</b> for medical relation ex- traction.</td></tr>
<tr><td colspan="1" valign="top">[\[46\]](#_bookmark54)</td><td colspan="1" valign="top">The GatorTron-large model achieved the best F1 score of <b>0.9000</b> for clinical concept ex- traction and <b>0.9627</b> for medical relation extraction.</td></tr>
<tr><td colspan="1" valign="top">[\[124\]](#_bookmark132)</td><td colspan="1" valign="top">The multicenter Transformers- based model achieved an over- all F1 score of <b>84.77%</b> on the PsyNIT dataset.</td></tr>
<tr><td colspan="1" valign="top">[\[76\]](#_bookmark84)</td><td colspan="1" valign="top">The BERT-D2 model achieved an F1 score of <b>81.97%</b> on the DDI Extraction 2013 corpus.</td></tr>
<tr><td colspan="1" rowspan="2" valign="top">BERTScore</td><td colspan="1" rowspan="2" valign="top">BERTScore calculates similarity scores between tokens in candidate and refer- ence sentences, using contextual embed- dings.</td><td colspan="1" valign="top">[\[125\]](#_bookmark133)</td><td colspan="1" valign="top">-</td></tr>
<tr><td colspan="1" valign="top">[\[85\]](#_bookmark93)</td><td colspan="1" valign="top">The Longformer-Encoder- Decoder (LEDlarge-PubMed) model achieved the best BERTScore F1 of <b>70.7</b>.</td></tr>
<tr><td colspan="1" valign="top">Human Evaluation</td><td colspan="1" valign="top">Involves expert human assessors rating the quality of model-generated content, providing qualitative insights into its per- formance.</td><td colspan="1" valign="top">[\[126\]](#_bookmark134)</td><td colspan="1" valign="top">The median performance for all human SCORE users was <b>65%</b>, whereas ChatGPT correctly answered <b>71%</b> of multiple-choice SCORE questions and <b>68%</b> of Data-B questions.</td></tr>
</table>



![](Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.015.jpeg)

Figure 5: Challenges of Large Language Models in Healthcare


in medical research with the critical requirement to protect private patient information [[132](#_bookmark140)]. LLMs’ ability to find potentially revealing patterns in large amounts of health data, even when anonymized, poses a serious privacy risk. This necessitates strict regulations and technical protections. Anonymizing data more effectively is crucial, as are algorithms designed to spot and prevent the re-identification of individuals. Ongoing monitoring of what LLMs produce is vital to ensure privacy isn’t accidentally compromised. Implementing these measures helps guarantee responsible use of sensitive data, allowing LLMs to be used ethically in healthcare while still respecting patient privacy. To ensure the ethical use of LLMs in healthcare, strong governance frameworks must extend beyond basic privacy laws. Proactive policies should anticipate challenges, and experts need to verify LLMs meet ethical guidelines. Engaging patients and healthcare providers in the development process promotes transparency and maintains trust in how health data is used within these systems.


1. ## <a name="bias and fairness"></a>**Bias and Fairness**

Researching ways to tackle and reduce biases in language models, while also comprehending their ethical ramifications, represents a pivotal research domain. It is imperative to create techniques for identifying, alleviating, and forestalling biases in large language models. A primary concern associated with Large Language Models (LLMs) pertains to the risk of producing misinformation or biased outputs. These models, drawing from extensive text data, encompass both dependable and unreliable sources, which can inadvertently result in the generation of inaccurate or misleading information. Furthermore, if the training data incorporates biases, such as gender or racial biases prevalent within scientific literature, LLMs can perpetuate and magnify these biases in their generated content.

To ensure the reliability and accuracy of information derived from LLMs, researchers must exercise caution and implement rigorous validation and verification processes. LLMs have the potential to amplify pre-existing biases inherent in their training data, particularly those linked to demographics, disease prevalence, or treatment outcomes. Consequently, the generated outputs may inadvertently reflect and perpetuate these biases, posing considerable challenges in achieving equitable and unbiased healthcare outcomes.

To address these challenges, researchers must remain vigilant in recognizing and mitigating biases within both the training data and the outputs generated by LLMs. This diligence is crucial for promoting fairness and inclusivity within the realm of biomedical research and healthcare applications, ultimately enhancing the ethical and equitable utility of LLMs in these domains [[132](#_bookmark140)]. Prioritizing bias mitigation in LLMs is essential. Researchers should curate and preprocess training data diligently to reduce inherent biases and address sources of inequality. Routine audits and evaluations are necessary to identify and correct biases in model training and deployment. Collaborative efforts between domain experts, ethicists, and data scientists can establish guidelines and best practices for unbiased LLM development, fostering fairness and inclusivity in biomedical research and healthcare.



1. ## <a name="hallucinations and fabricated informatio"></a>**Hallucinations and Fabricated Information**
Language models exhibit a proclivity for generating erroneous content, commonly referred to as hallucinations. This phenomenon is characterized by the production of text that appears plausible but lacks factual accuracy. This inherent trait poses a substantial risk when such generated content is employed for critical purposes, such as furnishing medical guidance or contributing to clinical decision-making processes. The consequences of relying on hallucinatory information in healthcare contexts can be profoundly detrimental, potentially leading to harmful or even catastrophic outcomes [\[133\].](#_bookmark141)

The gravity of this issue is exacerbated by the continuous advancement of Large Language Models (LLMs), which continually enhance their capacity to generate increasingly persuasive and believable hallucinations. Moreover, LLMs are often critiqued for their opacity, as they provide no discernible link to the original source of information, thereby creating a formidable barrier to the verification of the content they produce. To mitigate these risks, healthcare professionals must exercise extreme caution when utilizing LLMs to inform their decision-making processes, rigorously validating the accuracy and reliability of the generated information.

Current research endeavors are dedicated to addressing hallucination issues within Large Language Models (LLMs) in the healthcare and medical domain. The introduction of Med-HALT, a novel benchmark dataset, serves the purpose of evaluating hallucination phenomena in LLMs in medical contexts. Med-HALT encompasses two distinct test categories: reasoning-based and memory-based hallucination assessments. These tests have been meticulously designed to gauge the problem-solving and information retrieval capabilities of LLMs when operating within the medical domain [\[43\].](#_bookmark51)

1. ## <a name="legal and ethical reasons"></a>**Legal and Ethical Reasons**
Ethical concerns extend to the generation of potentially harmful content by LLMs, especially when delivering distressing medical diagnoses without providing adequate emotional support. Moreover, the blurring line between LLM-generated and human-written text poses a risk of misinformation dissemination, plagiarism, and impersonation.

To address these challenges, rigorous auditing and evaluation of LLMs are essential, along with the development of regulations for their medical use. Thoughtful selection of training datasets, particularly within the medical domain, is crucial to ensure the responsible handling of sensitive data. These measures collectively strive to strike a balance between harnessing LLMs’ potential and safeguarding patient privacy and ethical standards [\[131\].](#_bookmark139)

The European Union’s AI Act and the United States’ Health Insurance Portability and Accountability Act (HIPAA) are two significant regulatory frameworks impacting the deployment of AI in healthcare. The AI Act introduces comprehensive regulations, including the Artificial Intelligence Liability Directive (AILD), which addresses liability for AI-related damages. This directive ensures that victims are compensated and that preventive measures are cost-effective. The AI Act classifies General Purpose AI (GPAI) models and imposes specific obligations on providers, including technical documentation, risk assessments, and transparency about training data [\[134\].](#_bookmark142)

In the United States, HIPAA sets stringent standards for the protection of patient data, impacting how LLMs handle sensitive information. Compliance with HIPAA requires robust data encryption, regular security assessments, and strict access controls to protect patient information. These regulations ensure that LLMs used in healthcare settings adhere to high standards of privacy and security, mitigating risks associated with data breaches and unauthorized access.

Other relevant laws and compliance frameworks include the General Data Protection Regulation (GDPR) in the EU, which emphasizes data protection and privacy, and the Medical Device Regulation (MDR) that ensures the safety and efficacy of AI-driven medical devices. These regulations collectively impact the deployment of generative AI in healthcare by ensuring legal accountability, protecting patient data, and promoting ethical standards in AI development and application.

The implementation of regulatory frameworks such as the EU’s AI Act, HIPAA, GDPR, and MDR significantly impacts the deployment of LLMs and generative AI in healthcare by ensuring transparency, data protection, and patient safety. These regulations necessitate detailed documentation of AI models, advanced data encryption, strict access controls, and rigorous clinical testing, thereby increasing development costs and timelines. However, they also promote reliability, legal accountability, and ethical standards in AI development, fostering trust among users and stakeholders and encouraging the responsible and wider adoption of AI technologies in healthcare [\[135\].](#_bookmark143)

1. # <a name="conclusion"></a>**Conclusion**
In conclusion, the integration of large language models (LLMs) in healthcare showcases immense potential for enhancing clinical language understanding and medical applications. These models offer versatility and sophistication, from



named entity recognition to question-answering, bolstering decision support and information retrieval. Comparative analyses of state-of-the-art LLMs and open-source options emphasize their significance in healthcare, promoting innovation and collaboration. Performance metrics drive continuous improvement but call for rigorous evaluation standards, considering potential biases and ethical concerns. However, challenges persist, including the need for robust training data, bias mitigation, and data privacy. LLMs in healthcare necessitate further research and interdisciplinary cooperation. LLMs promise transformative benefits, but their full potential hinges on addressing these challenges and upholding ethical standards. The ongoing journey of LLMs in healthcare demands collective efforts to harness their power for improved patient care while ensuring ethical and responsible application.

# **References**
1. <a name="_bookmark9"></a>Henglin Shi, Wei Peng, Haoyu Chen, Xin Liu, and Guoying Zhao. Multiscale 3d-shift graph convolution network for emotion recognition from human actions. *IEEE Intelligent Systems*, 37(4):103–110, 2022.
1. <a name="_bookmark10"></a>	Hao Yu, Xu Cheng, Wei Peng, Weihao Liu, and Guoying Zhao. Modality unifying network for visible-infrared person re-identification. In *Proceedings of the IEEE/CVF International Conference on Computer Vision*, pages 11185–11195, 2023.
1. <a name="_bookmark11"></a>Yante Li, Wei Peng, and Guoying Zhao. Micro-expression action unit detection with dual-view attentive similarity-preserving knowledge distillation. In *2021 16th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)*, pages 01–08. IEEE, 2021.
1. <a name="_bookmark12"></a>	Xiaopeng Hong, Wei Peng, Mehrtash Harandi, Ziheng Zhou, Matti Pietikäinen, and Guoying Zhao. Char- acterizing subtle facial movements via riemannian manifold. *ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)*, 15(3s):1–24, 2019.
1. <a name="_bookmark13"></a>Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, and Erik Cambria. A survey of large language models for healthcare: from data, technology, and applications to accountability and ethics. *arXiv preprint arXiv:2310.05694*, 2023.
1. <a name="_bookmark14"></a>Yuqing Wang, Yun Zhao, and Linda Petzold. Are large language models ready for healthcare? a comparative study on clinical language understanding. *arXiv preprint arXiv:2304.05368*, 2023.
1. <a name="_bookmark15"></a>Ping Yu, Hua Xu, Xia Hu, and Chao Deng. Leveraging generative ai and large language models: a comprehensive roadmap for healthcare integration. In *Healthcare*, volume 11, page 2776. MDPI, 2023.
1. <a name="_bookmark16"></a>	Wei Peng, Li Feng, Guoying Zhao, and Fang Liu. Learning optimal k-space acquisition and reconstruction using physics-informed neural networks. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages 20794–20803, 2022.
1. <a name="_bookmark17"></a>	Wei Peng, Ehsan Adeli, Tomas Bosschieter, Sang Hyun Park, Qingyu Zhao, and Kilian M Pohl. Generating realistic brain mris via a conditional diffusion probabilistic model. In *International Conference on Medical Image Computing and Computer-Assisted Intervention*, pages 14–24. Springer, 2023.
1. <a name="_bookmark18"></a>	Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. *Advances in neural information processing systems*, 33:1877–1901, 2020.
1. <a name="_bookmark19"></a>OpenAI. Gpt-4 technical report, 2023.
1. <a name="_bookmark20"></a>Chaoning Zhang, Chenshuang Zhang, Chenghao Li, Yu Qiao, Sheng Zheng, Sumit Kumar Dam, Mengchun Zhang, Jung Uk Kim, Seong Tae Kim, Jinwoo Choi, et al. One small step for generative ai, one giant leap for agi: A complete survey on chatgpt in aigc era. *arXiv preprint arXiv:2304.06488*, 2023.
1. <a name="_bookmark21"></a>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. *arXiv preprint arXiv:2302.13971*, 2023.
1. <a name="_bookmark22"></a>Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang. Biobert: a pre-trained biomedical language representation model for biomedical text mining. *Bioinformatics*, 36(4):1234–1240, 2020.
1. <a name="_bookmark23"></a>Kexin Huang, Jaan Altosaar, and Rajesh Ranganath. Clinicalbert: Modeling clinical notes and predicting hospital readmission. *arXiv preprint arXiv:1904.05342*, 2019.
1. <a name="_bookmark24"></a>Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, and Sebastian Riedel. Language models as knowledge bases? *arXiv preprint arXiv:1909.01066*, 2019.



1. <a name="_bookmark25"></a>Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understanding by generative pre-training. 2018.
1. <a name="_bookmark26"></a>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. *arXiv preprint arXiv:2204.02311*, 2022.
1. <a name="_bookmark27"></a>Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. *OpenAI blog*, 1(8):9, 2019.
1. <a name="_bookmark28"></a>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. *Advances in neural information processing systems*, 30, 2017.
1. <a name="_bookmark29"></a>William Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. *The Journal of Machine Learning Research*, 23(1):5232–5270, 2022.
1. <a name="_bookmark30"></a>Nan Du, Yanping Huang, Andrew M Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi Zhou, Adams Wei Yu, Orhan Firat, et al. Glam: Efficient scaling of language models with mixture-of-experts. In *International Conference on Machine Learning*, pages 5547–5569. PMLR, 2022.
1. <a name="_bookmark31"></a>Haifeng Wang, Jiwei Li, Hua Wu, Eduard Hovy, and Yu Sun. Pre-trained language models and their applications.

   *Engineering*, 2022.

1. <a name="_bookmark32"></a>Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. *arXiv preprint arXiv:2109.01652*, 2021.
1. <a name="_bookmark33"></a>Daquan Zhou, Yujun Shi, Bingyi Kang, Weihao Yu, Zihang Jiang, Yuan Li, Xiaojie Jin, Qibin Hou, and Jiashi Feng. Refiner: Refining self-attention for vision transformers. *arXiv preprint arXiv:2106.03714*, 2021.
1. <a name="_bookmark34"></a>Zabir Al Nazi, Fazla Rabbi Mashrur, Md Amirul Islam, and Shumit Saha. Fibro-cosanet: pulmonary fibrosis prognosis prediction using a convolutional self attention network. *Physics in Medicine & Biology*, 66(22):225013, <a name="_bookmark35"></a>2021.
1. Yaru Hao, Li Dong, Furu Wei, and Ke Xu. Self-attention attribution: Interpreting information interactions inside transformer. In *Proceedings of the AAAI Conference on Artificial Intelligence*, volume 35, pages 12963–12971, <a name="_bookmark36"></a>2021.
1. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models. In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition*, pages 10684–10695, 2022.
1. <a name="_bookmark37"></a>Vipula Rawte, Amit Sheth, and Amitava Das. A survey of hallucination in large foundation models. *arXiv preprint arXiv:2309.05922*, 2023.
1. <a name="_bookmark38"></a>Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen. A survey on multimodal large language models. *arXiv preprint arXiv:2306.13549*, 2023.
1. <a name="_bookmark39"></a>	Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. Visual chatgpt: Talking, drawing and editing with visual foundation models. *arXiv preprint arXiv:2303.04671*, 2023.
1. <a name="_bookmark40"></a>	Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models. In *International conference on machine learning*, pages 19730–19742. PMLR, 2023.
1. <a name="_bookmark41"></a>Zhuofan Zong, Bingqi Ma, Dazhong Shen, Guanglu Song, Hao Shao, Dongzhi Jiang, Hongsheng Li, and Yu Liu. Mova: Adapting mixture of vision experts to multimodal context. *arXiv preprint arXiv:2404.13046*, 2024.
1. <a name="_bookmark42"></a>Bin Lin, Zhenyu Tang, Yang Ye, Jiaxi Cui, Bin Zhu, Peng Jin, Junwu Zhang, Munan Ning, and Li Yuan. Moe-llava: Mixture of experts for large vision-language models. *arXiv preprint arXiv:2401.15947*, 2024.
1. <a name="_bookmark43"></a>	Jiachen Li, Xinyao Wang, Sijie Zhu, Chia-Wen Kuo, Lu Xu, Fan Chen, Jitesh Jain, Humphrey Shi, and Longyin Wen. Cumo: Scaling multimodal llm with co-upcycled mixture-of-experts. *arXiv preprint arXiv:2405.05949*, <a name="_bookmark44"></a>2024.
1. Arun James Thirunavukarasu, Darren Shu Jeng Ting, Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, and Daniel Shu Wei Ting. Large language models in medicine. *Nature Medicine*, pages 1–11, 2023.
1. <a name="_bookmark45"></a>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. *arXiv preprint arXiv:1810.04805*, 2018.
1. <a name="_bookmark46"></a>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. *arXiv preprint arXiv:1907.11692*, 2019.



1. <a name="_bookmark47"></a>Yanis Labrak, Adrien Bazoge, Emmanuel Morin, Pierre-Antoine Gourraud, Mickael Rouvier, and Richard Dufour. Biomistral: A collection of open-source pretrained large language models for medical domains. *arXiv preprint arXiv:2402.10373*, 2024.
1. <a name="_bookmark48"></a>Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal, et al. Towards expert-level medical question answering with large language models. *arXiv preprint arXiv:2305.09617*, 2023.
1. <a name="_bookmark49"></a>Zhengliang Liu, Yiwei Li, Peng Shu, Aoxiao Zhong, Longtao Yang, Chao Ju, Zihao Wu, Chong Ma, Jie Luo, Cheng Chen, et al. Radiology-llama2: Best-in-class large language model for radiology. *arXiv preprint arXiv:2309.06419*, 2023.
1. <a name="_bookmark50"></a>Zhengliang Liu, Xiaowei Yu, Lu Zhang, Zihao Wu, Chao Cao, Haixing Dai, Lin Zhao, Wei Liu, Dinggang Shen, Quanzheng Li, et al. Deid-gpt: Zero-shot medical text de-identification by gpt-4. *arXiv preprint arXiv:2303.11032*, 2023.
1. <a name="_bookmark51"></a>Logesh Kumar Umapathi, Ankit Pal, and Malaikannan Sankarasubbu. Med-halt: Medical domain hallucination test for large language models. *arXiv preprint arXiv:2307.15343*, 2023.
1. <a name="_bookmark52"></a>Zihao Zhao, Sheng Wang, Jinchen Gu, Yitao Zhu, Lanzhuju Mei, Zixu Zhuang, Zhiming Cui, Qian Wang, and Dinggang Shen. Chatcad+: Towards a universal and reliable interactive cad using llms. *arXiv preprint arXiv:2305.15964*, 2023.
1. <a name="_bookmark53"></a>Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu. Biogpt: generative pre-trained transformer for biomedical text generation and mining. *Briefings in Bioinformatics*, 23(6):bbac409, <a name="_bookmark54"></a>2022.
1. Xi Yang, Aokun Chen, Nima PourNejatian, Hoo Chang Shin, Kaleb E Smith, Christopher Parisien, Colin Compas, Cheryl Martin, Mona G Flores, Ying Zhang, et al. Gatortron: A large clinical language model to unlock patient information from unstructured electronic health records. *arXiv preprint arXiv:2203.03540*, 2022.
1. <a name="_bookmark55"></a>Hongyi Yuan, Zheng Yuan, Ruyi Gan, Jiaxing Zhang, Yutao Xie, and Sheng Yu. Biobart: Pretraining and evaluation of a biomedical generative language model. *arXiv preprint arXiv:2204.03905*, 2022.
1. <a name="_bookmark56"></a>Qiuhao Lu, Dejing Dou, and Thien Nguyen. Clinicalt5: A generative language model for clinical text. In

   *Findings of the Association for Computational Linguistics: EMNLP 2022*, pages 5436–5443, 2022.

1. <a name="_bookmark57"></a>Zheng Yuan, Yijia Liu, Chuanqi Tan, Songfang Huang, and Fei Huang. Improving biomedical pretrained language models with knowledge. *arXiv preprint arXiv:2104.10344*, 2021.
1. <a name="_bookmark58"></a>	Desh Raj, Sunil Sahu, and Ashish Anand. Learning local and global contexts using a convolutional recurrent net- work model for relation classification in biomedical text. In *Proceedings of the 21st conference on computational natural language learning (CoNLL 2017)*, pages 311–321, 2017.
1. <a name="_bookmark59"></a>Chen Lyu, Bo Chen, Yafeng Ren, and Donghong Ji. Long short-term memory rnn for biomedical named entity recognition. *BMC bioinformatics*, 18:1–11, 2017.
1. <a name="_bookmark60"></a>Ishita Dasgupta, Andrew K Lampinen, Stephanie CY Chan, Antonia Creswell, Dharshan Kumaran, James L McClelland, and Felix Hill. Language models show human-like content effects on reasoning. *arXiv preprint arXiv:2207.07051*, 2022.
1. <a name="_bookmark61"></a>	Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. Large language models encode clinical knowledge. *Nature*, pages 1–9, 2023.
1. <a name="_bookmark62"></a>Zekai Chen, Mariann Micsinai Balan, and Kevin Brown. Language models are few-shot learners for prognostic prediction. *arXiv e-prints*, pages arXiv–2302, 2023.
1. <a name="_bookmark63"></a>Vivian Weiwen Xue, Pinggui Lei, and William C Cho. The potential impact of chatgpt in clinical and translational medicine. *Clinical and Translational Medicine*, 13(3), 2023.
1. <a name="_bookmark64"></a>Zekai Chen, Mariann Micsinai Balan, and Kevin Brown. Boosting transformers and language models for clinical prediction in immunotherapy. *arXiv preprint arXiv:2302.12692*, 2023.
1. <a name="_bookmark65"></a>Hongyang Li, Richard C Gerkin, Alyssa Bakke, Raquel Norel, Guillermo Cecchi, Christophe Laudamiel, Masha Y Niv, Kathrin Ohla, John E Hayes, Valentina Parma, et al. Text-based predictions of covid-19 diagnosis from self-reported chemosensory descriptions. *Communications Medicine*, 3(1):104, 2023.
1. <a name="_bookmark66"></a>	Chengsheng Mao, Jie Xu, Luke Rasmussen, Yikuan Li, Prakash Adekkanattu, Jennifer Pacheco, Borna Bonakdar- pour, Robert Vassar, Li Shen, Guoqian Jiang, et al. Ad-bert: Using pre-trained language model to predict the progression from mild cognitive impairment to alzheimer’s disease. *Journal of Biomedical Informatics*, 144:104442, 2023.



1. <a name="_bookmark67"></a>Felix Agbavor and Hualou Liang. Predicting dementia from spontaneous speech using large language models.

   *PLOS Digital Health*, 1(12):e0000168, 2022.

1. <a name="_bookmark68"></a>Desirée Bill and Theodor Eriksson. Fine-tuning a llm using reinforcement learning from human feedback for a therapy chatbot application, 2023.
1. <a name="_bookmark69"></a>Michael Balas and Edsel B Ing. Conversational ai models for ophthalmic diagnosis: Comparison of chatgpt and the isabel pro differential diagnosis generator. *JFO Open Ophthalmology*, 1:100005, 2023.
1. <a name="_bookmark70"></a>Tin Lai, Yukun Shi, Zicong Du, Jiajie Wu, Ken Fu, Yichao Dou, and Ziqi Wang. Psy-llm: Scaling up global mental health psychological services with ai-based large language models. *arXiv preprint arXiv:2307.11991*, <a name="_bookmark71"></a>2023.
1. Maham Bilal, Yumna Jamil, Dua Rana, and Hussain Haider Shah. Enhancing awareness and self-diagnosis of obstructive sleep apnea using ai-powered chatbots: The role of chatgpt in revolutionizing healthcare. *Annals of Biomedical Engineering*, pages 1–3, 2023.
1. <a name="_bookmark72"></a>Mohd Javaid, Abid Haleem, and Ravi Pratap Singh. Chatgpt for healthcare services: An emerging stage for an innovative perspective. *BenchCouncil Transactions on Benchmarks, Standards and Evaluations*, 3(1):100105, <a name="_bookmark73"></a>2023.
1. Stephen R Ali, Thomas D Dobbs, Hayley A Hutchings, and Iain S Whitaker. Using chatgpt to write patient clinic letters. *The Lancet Digital Health*, 5(4):e179–e181, 2023.
1. <a name="_bookmark74"></a>Josh Nguyen and Christopher A Pepping. The application of chatgpt in healthcare progress notes: A commentary from a clinical and research perspective. *Clinical and Translational Medicine*, 13(7), 2023.
1. <a name="_bookmark75"></a>	Harriet Louise Walker, Shahi Ghani, Christoph Kuemmerli, Christian Andreas Nebiker, Beat Peter Müller, Dimitri Aristotle Raptis, and Sebastian Manuel Staubli. Reliability of medical information provided by chatgpt: Assessment against clinical guidelines and patient information quality instrument. *Journal of Medical Internet Research*, 25:e47479, 2023.
1. <a name="_bookmark76"></a>	Linta Iftikhar et al. Docgpt: Impact of chatgpt-3 on health services as a virtual doctor. *EC Paediatrics*, 12(1):45–55, 2023.
1. <a name="_bookmark77"></a>Hao Yang, Jiaxi Li, Siru Liu, Lei Du, Xiali Liu, Yong Huang, Qingke Shi, and Jialin Liu. Exploring the potential of large language models in personalized diabetes treatment strategies. *medRxiv*, pages 2023–06, 2023.
1. <a name="_bookmark78"></a>Sheng Wang, Zihao Zhao, Xi Ouyang, Qian Wang, and Dinggang Shen. Chatcad: Interactive computer-aided diagnosis on medical image using large language models. *arXiv preprint arXiv:2302.07257*, 2023.
1. <a name="_bookmark79"></a>Vera Sorin, Yiftach Barash, Eli Konen, and Eyal Klang. Large language models for oncological applications.

   *Journal of Cancer Research and Clinical Oncology*, pages 1–4, 2023.

1. <a name="_bookmark80"></a>Rubeta N Matin, Eleni Linos, and Neil Rajan. Leveraging large language models in dermatology, 2023.
1. <a name="_bookmark81"></a>Malik Sallam. The utility of chatgpt as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and potential limitations. *medRxiv*, pages 2023–02, <a name="_bookmark82"></a>2023.
1. Liyan Tang, Zhaoyi Sun, Betina Idnay, Jordan G Nestor, Ali Soroush, Pierre A Elias, Ziyang Xu, Ying Ding, Greg Durrett, Justin F Rousseau, et al. Evaluating large language models on medical evidence summarization. *npj Digital Medicine*, 6(1):158, 2023.
1. <a name="_bookmark83"></a>Zhichao Liu, Ruth A Roberts, Madhu Lal-Nag, Xi Chen, Ruili Huang, and Weida Tong. Ai-based language models powering drug discovery and development. *Drug Discovery Today*, 26(11):2593–2607, 2021.
1. <a name="_bookmark84"></a>Tanmoy Tapos Datta, Pintu Chandra Shill, and Zabir Al Nazi. Bert-d2: Drug-drug interaction extraction using bert. In *2022 International Conference for Advancement in Technology (ICONAT)*, pages 1–6. IEEE, 2022.
1. <a name="_bookmark85"></a>	Francesca Grisoni. Chemical language models for de novo drug design: Challenges and opportunities. *Current Opinion in Structural Biology*, 79:102527, 2023.
1. <a name="_bookmark86"></a>Gökçe Uludog˘an, Elif Ozkirimli, Kutlu O Ulgen, Nilgün Karalı, and Arzucan Özgür. Exploiting pretrained biochemical language models for targeted drug design. *Bioinformatics*, 38(Supplement\_2):ii155–ii161, 2022.
1. <a name="_bookmark87"></a>Lei Ma, Jincong Han, Zhaoxin Wang, and Dian Zhang. Cephgpt-4: An interactive multimodal cephalometric measurement and diagnostic system with visual large language model. *arXiv preprint arXiv:2307.07518*, 2023.
1. <a name="_bookmark88"></a>	Firas Khader, Gustav Mueller-Franzes, Tianci Wang, Tianyu Han, Soroosh Tayebi Arasteh, Christoph Haarburger, Johannes Stegmaier, Keno Bressem, Christiane Kuhl, Sven Nebelung, et al. Medical diagnosis with large scale multimodal transformers–leveraging diverse data for more accurate diagnosis. *arXiv preprint arXiv:2212.09162*, 2022.



1. <a name="_bookmark89"></a>Omkar Thawkar, Abdelrahman Shaker, Sahal Shaji Mullappilly, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan, Jorma Laaksonen, and Fahad Shahbaz Khan. Xraygpt: Chest radiographs summarization using medical vision-language models. *arXiv preprint arXiv:2306.07971*, 2023.
1. <a name="_bookmark90"></a>Jiaxiang Liu, Tianxiang Hu, Yan Zhang, Xiaotang Gai, Yang Feng, and Zuozhu Liu. A chatgpt aided explainable framework for zero-shot medical image diagnosis. *arXiv preprint arXiv:2307.01981*, 2023.
1. <a name="_bookmark91"></a>	Masoud Monajatipoor, Mozhdeh Rouhsedaghat, Liunian Harold Li, C-C Jay Kuo, Aichi Chien, and Kai-Wei Chang. Berthop: An effective vision-and-language model for chest x-ray disease diagnosis. In *International Conference on Medical Image Computing and Computer-Assisted Intervention*, pages 725–734. Springer, 2022.
1. <a name="_bookmark92"></a>Alireza Roshanzamir, Hamid Aghajan, and Mahdieh Soleymani Baghshah. Transformer-based deep neural network language models for alzheimer’s disease risk assessment from targeted speech. *BMC Medical Informatics and Decision Making*, 21:1–14, 2021.
1. <a name="_bookmark93"></a>	John Giorgi, Augustin Toma, Ronald Xie, Sondra Chen, Kevin An, Grace Zheng, and Bo Wang. Wanglab at mediqa-chat 2023: Clinical note generation from doctor-patient conversations using large language models. In *Proceedings of the 5th Clinical Natural Language Processing Workshop*, pages 323–334, 2023.
1. <a name="_bookmark94"></a>Guangming Huang, Yingya Li, Shoaib Jameel, Yunfei Long, and Giorgos Papanastasiou. From explainable to interpretable deep learning for natural language processing in healthcare: How far from reality? *Computational and Structural Biotechnology Journal*, 2024.
1. <a name="_bookmark95"></a>	Hans-Christian Thorsen-Meyer, Davide Placido, Benjamin Skov Kaas-Hansen, Anna P Nielsen, Theis Lange, Annelaura B Nielsen, Palle Toft, Jens Schierbeck, Thomas Strøm, Piotr J Chmura, et al. Discrete-time survival analysis in the critically ill: a deep learning approach using heterogeneous data. *NPJ digital medicine*, 5(1):142, <a name="_bookmark96"></a>2022.
1. Alwin Yaoxian Zhang, Sean Shao Wei Lam, Marcus Eng Hock Ong, Phua Hwee Tang, and Ling Ling Chan. Explainable ai: classification of mri brain scans orders for quality improvement. In *Proceedings of the 6th IEEE/ACM international conference on big data computing, applications and technologies*, pages 95–102, 2019.
1. <a name="_bookmark97"></a>Ozan Ozyegen, Devika Kabe, and Mucahit Cevik. Word-level text highlighting of medical texts for telehealth services. *Artificial Intelligence in Medicine*, 127:102284, 2022.
1. <a name="_bookmark98"></a>Adam Gabriel Dobrakowski, Agnieszka Mykowiecka, Małgorzata Marciniak, Wojciech Jaworski, and Prze- mysław Biecek. Interpretable segmentation of medical free-text records based on word embeddings. *Journal of Intelligent Information Systems*, 57:447–465, 2021.
1. <a name="_bookmark99"></a>Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M Churpek, and Majid Afshar. Leveraging a medical knowledge graph into large language models for diagnosis prediction. *arXiv preprint arXiv:2308.14321*, 2023.
1. <a name="_bookmark100"></a>Kailai Yang, Shaoxiong Ji, Tianlin Zhang, Qianqian Xie, Ziyan Kuang, and Sophia Ananiadou. Towards interpretable mental health analysis with large language models. *arXiv preprint arXiv:2304.03347*, 2023.
1. <a name="_bookmark101"></a>Shengxin Hong, Liang Xiao, Xin Zhang, and Jianxia Chen. Argmed-agents: Explainable clinical decision reasoning with large language models via argumentation schemes. *arXiv preprint arXiv:2403.06294*, 2024.
1. <a name="_bookmark102"></a>	Kailai Yang, Tianlin Zhang, Ziyan Kuang, Qianqian Xie, Jimin Huang, and Sophia Ananiadou. Mentallama: interpretable mental health analysis on social media with large language models. In *Proceedings of the ACM on Web Conference 2024*, pages 4489–4500, 2024.
1. <a name="_bookmark103"></a>Thomas Savage, Ashwin Nayak, Robert Gallo, Ekanath Rangan, and Jonathan H Chen. Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine. *NPJ Digital Medicine*, 7(1):20, <a name="_bookmark104"></a>2024.
1. Bo Lin, Yingjing Xu, Xuanwen Bao, Zhou Zhao, Zuyong Zhang, Zhouyang Wang, Jie Zhang, Shuiguang Deng, and Jianwei Yin. Skingen: An explainable dermatology diagnosis-to-generation framework with interactive vision-language models. *arXiv preprint arXiv:2404.14755*, 2024.
1. <a name="_bookmark105"></a>Min Hun Lee and Chong Jun Chew. Understanding the effect of counterfactual explanations on trust and reliance on ai for human-ai collaborative clinical decision making. *Proceedings of the ACM on Human-Computer Interaction*, 7(CSCW2):1–22, 2023.
1. <a name="_bookmark106"></a>Denis Jered McInerney, Geoffrey Young, Jan-Willem van de Meent, and Byron C Wallace. Chill: zero- shot custom interpretable feature extraction from clinical notes with large language models. *arXiv preprint arXiv:2302.12343*, 2023.
1. <a name="_bookmark107"></a>	Usman Naseem, Matloob Khushi, and Jinman Kim. Vision-language transformer for interpretable pathology visual question answering. *IEEE Journal of Biomedical and Health Informatics*, 27(4):1681–1690, 2022.



1. <a name="_bookmark108"></a>S Park, G Kim, Y Oh, JB Seo, SM Lee, JH Kim, S Moon, JK Lim, and JC Ye. Vision transformer for covid-19 cxr diagnosis using chest x-ray feature corpus. arxiv 2021. *arXiv preprint arXiv:2103.07055*.
1. <a name="_bookmark109"></a>Jie Pan. Large language model for molecular chemistry. *Nature Computational Science*, 3(1):5–5, 2023.
1. <a name="_bookmark110"></a>Juhao Liang, Ziwei Wang, Zhuoheng Ma, Jianquan Li, Zhiyi Zhang, Xiangbo Wu, and Benyou Wang. Online training of large language models: Learn while chatting. *arXiv preprint arXiv:2403.04790*, 2024.
1. <a name="_bookmark111"></a>Tianshi Che, Ji Liu, Yang Zhou, Jiaxiang Ren, Jiwen Zhou, Victor S Sheng, Huaiyu Dai, and Dejing Dou. Federated learning of large language models with parameter-efficient prompt tuning and adaptive optimization. *arXiv preprint arXiv:2310.15080*, 2023.
1. <a name="_bookmark112"></a>	Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, and Mengnan Du. Explainability for large language models: A survey. *ACM Transactions on Intelligent Systems and Technology*, 15(2):1–38, 2024.
1. <a name="_bookmark113"></a>Yubin Kim, Xuhai Xu, Daniel McDuff, Cynthia Breazeal, and Hae Won Park. Health-llm: Large language models for health prediction via wearable sensor data. *arXiv preprint arXiv:2401.06866*, 2024.
1. <a name="_bookmark114"></a>Saurabh Pahune and Noopur Rewatkar. Large language models and generative ai’s expanding role in healthcare. <a name="_bookmark115"></a>2024.
1. Sandeep Reddy, Wendy Rogers, Ville-Petteri Makinen, Enrico Coiera, Pieta Brown, Markus Wenzel, Eva Weicken, Saba Ansari, Piyush Mathur, Aaron Casey, et al. Evaluation framework to guide implementation of ai systems into healthcare settings. *BMJ health & care informatics*, 28(1), 2021.
1. <a name="_bookmark116"></a>Sandeep Reddy. Evaluating large language models for use in healthcare: A framework for translational value assessment. *Informatics in Medicine Unlocked*, page 101304, 2023.
1. <a name="_bookmark117"></a>Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2 technical report. *arXiv preprint arXiv:2305.10403*, <a name="_bookmark118"></a>2023.
1. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. *arXiv preprint arXiv:2009.03300*, 2020.
1. <a name="_bookmark119"></a>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. *arXiv preprint arXiv:2107.03374*, 2021.
1. <a name="_bookmark120"></a>Klu AI. Mmlu benchmark (massive multi-task language understanding), 2024. Accessed: 2024-07-08.
1. <a name="_bookmark121"></a>Qiao Jin, Bhuwan Dhingra, William W Cohen, and Xinghua Lu. Probing biomedical embeddings from language models. *arXiv preprint arXiv:1904.02181*, 2019.
1. <a name="_bookmark122"></a>Andreas Mayr, Günter Klambauer, Thomas Unterthiner, and Sepp Hochreiter. Deeptox: toxicity prediction using deep learning. *Frontiers in Environmental Science*, 3:80, 2016.
1. <a name="_bookmark123"></a>Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W Cohen, and Xinghua Lu. Pubmedqa: A dataset for biomedical research question answering. *arXiv preprint arXiv:1909.06146*, 2019.
1. <a name="_bookmark124"></a>Papers with Code. Medical papers with code, 2024. Accessed: 2024-07-08.
1. <a name="_bookmark125"></a>Jonghyun Lee, In-Soo Myeong, and Yun Kim. The drug-like molecule pre-training strategy for drug discovery.

   *IEEE Access*, 11:61680–61687, 2023.

1. <a name="_bookmark126"></a>Wenxiong Liao, Zhengliang Liu, Haixing Dai, Shaochen Xu, Zihao Wu, Yiyang Zhang, Xiaoke Huang, Dajiang Zhu, Hongmin Cai, Tianming Liu, et al. Differentiate chatgpt-generated and human-written medical texts. *arXiv preprint arXiv:2304.11567*, 2023.
1. <a name="_bookmark127"></a>	Andrea Manoel, Mirian del Carmen Hipolito Garcia, Tal Baumel, Shize Su, Jialei Chen, Robert Sim, Dan Miller, Danny Karmon, and Dimitrios Dimitriadis. Federated multilingual models for medical transcript analysis. In *Conference on Health, Inference, and Learning*, pages 147–162. PMLR, 2023.
1. <a name="_bookmark128"></a>	Yuhui Zhang, Allen Nie, Ashley Zehnder, Rodney L Page, and James Zou. Vettag: improving automated veterinary diagnosis coding via large-scale language modeling. *NPJ digital medicine*, 2(1):35, 2019.
1. <a name="_bookmark129"></a>Guangyu Wang, Guoxing Yang, Zongxin Du, Longjun Fan, and Xiaohu Li. Clinicalgpt: Large language models finetuned with diverse medical data and comprehensive evaluation. *arXiv preprint arXiv:2306.09968*, 2023.
1. <a name="_bookmark130"></a>Jianquan Li, Xidong Wang, Xiangbo Wu, Zhiyi Zhang, Xiaolong Xu, Jie Fu, Prayag Tiwari, Xiang Wan, and Benyou Wang. Huatuo-26m, a large-scale chinese medical qa dataset. *arXiv preprint arXiv:2305.01526*, 2023.


![ref3]


1. <a name="_bookmark131"></a>Xi Yang, Aokun Chen, Nima PourNejatian, Hoo Chang Shin, Kaleb E Smith, Christopher Parisien, Colin Compas, Cheryl Martin, Anthony B Costa, Mona G Flores, et al. A large language model for electronic health records. *NPJ Digital Medicine*, 5(1):194, 2022.
1. <a name="_bookmark132"></a>Claudio Crema, Tommaso Mario Buonocore, Silvia Fostinelli, Enea Parimbelli, Federico Verde, Cira Fundarò, Marina Manera, Matteo Cotta Ramusino, Marco Capelli, Alfredo Costa, et al. Advancing italian biomedical information extraction with large language models: Methodological insights and multicenter practical application. *arXiv preprint arXiv:2306.05323*, 2023.
1. <a name="_bookmark133"></a>Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. Bertscore: Evaluating text generation with bert. *arXiv preprint arXiv:1904.09675*, 2019.
1. <a name="_bookmark134"></a>Brendin R Beaulieu-Jones, Sahaj Shah, Margaret T Berrigan, Jayson S Marwaha, Shuo-Lun Lai, and Gabriel A Brat. Evaluating capabilities of large language models: Performance of gpt4 on surgical knowledge assessments. *medRxiv*, pages 2023–07, 2023.
1. <a name="_bookmark135"></a>	Hazrat Ali, Junaid Qadir, Tanvir Alam, Mowafa Househ, and Zubair Shah. Chatgpt and large language models (llms) in healthcare: Opportunities and risks. 2023.
1. <a name="_bookmark136"></a>Giovanni Briganti. A clinician’s guide to large language models. *Future Medicine AI*, (0):FMAI, 2023.
1. <a name="_bookmark137"></a>Aleksa Bisercic, Mladen Nikolic, Mihaela van der Schaar, Boris Delibasic, Pietro Lio, and Andrija Petrovic. Interpretable medical diagnostics with structured data extraction by large language models. *arXiv preprint arXiv:2306.05052*, 2023.
1. <a name="_bookmark138"></a>Yan Jiang, Ruihong Qiu, Yi Zhang, and Peng-Fei Zhang. Balanced and explainable social media analysis for public health with large language models. *arXiv preprint arXiv:2309.05951*, 2023.
1. <a name="_bookmark139"></a>Jesutofunmi A Omiye, Haiwen Gui, Shawheen J Rezaei, James Zou, and Roxana Daneshjou. Large language models in medicine: the potentials and pitfalls. *arXiv preprint arXiv:2309.00087*, 2023.
1. <a name="_bookmark140"></a>Surendrabikram Thapa and Surabhi Adhikari. Chatgpt, bard, and large language models for biomedical research: Opportunities and pitfalls. *Annals of Biomedical Engineering*, pages 1–5, 2023.
1. <a name="_bookmark141"></a>	Shubo Tian, Qiao Jin, Lana Yeganova, Po-Ting Lai, Qingqing Zhu, Xiuying Chen, Yifan Yang, Qingyu Chen, Won Kim, Donald C Comeau, et al. Opportunities and challenges for chatgpt and large language models in biomedicine and health. *arXiv preprint arXiv:2306.10070*, 2023.
1. <a name="_bookmark142"></a>Claudio Novelli, Federico Casolari, Philipp Hacker, Giorgio Spedicato, and Luciano Floridi. Generative ai in eu law: liability, privacy, intellectual property, and cybersecurity. *arXiv preprint arXiv:2401.07348*, 2024.
1. <a name="_bookmark143"></a>	Philipp Hacker, Andreas Engel, and Marco Mauer. Regulating chatgpt and other large generative ai models. In *Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency*, pages 1112–1123, 2023.























22



[ref1]: Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.002.png
[ref2]: Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.005.png
[ref3]: Aspose.Words.216b72a2-da75-4381-9ce1-833331fe7cf2.006.png
